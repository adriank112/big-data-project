{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4a0e4f",
   "metadata": {},
   "source": [
    "# Engagement Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a106214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aaronquestel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aaronquestel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import ngrams\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce521682",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8eae24",
   "metadata": {},
   "source": [
    "remove stopwords,\n",
    "remove where likes/retweets = 0\n",
    "perform outlier analysis\n",
    "remove @'s and replace with @symbol\n",
    "remove url's and replace with 'url' text -these are both to see if having a mention or url in tweet improves engagement\n",
    "Make classes discreet, so have ranges for likes and retweets for ML classifier and get ranges by plotting graphs and seeing where most of the tweets lie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e04c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweet_engagement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e6785",
   "metadata": {},
   "source": [
    "To clean the text, all punctuation is removed so that we are only working with words for our machine learning model. Stop words, such as 'the', 'and', 'ok', etc which generally do not have a significant impact on the meaning of a sentence are be removed so as to reduce the number of features (words) in our dataset after the TFIDF vectorizer is applied. Also, each word is lemmatized, i.e. reduced to it's lemma, to again reduce the number of features that will appear in the dataset after applying the TFIDF vectorizer. Lemmatization was done rather than stemming since stemming was found to haphazardly cut off the ends of words, sometimes causing confusion when interpreting the stemmed word, e.g. 'dying' would become 'dy', wheresas lemmatizing the word was more readable, e.g. 'dying' would become 'die'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7df742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) #remove punctuation\n",
    "    text = re.sub(\"\\@\\S+\", \"@\", text) #replace mentions with '@' character so can see if mention in tweet or not\n",
    "    stop_words = set(stopwords.words('english'))   #create set with english stopwords\n",
    "    tokenized_review = word_tokenize(text)     #tokenize text, i.e. turn into list of words\n",
    "#     stemmer = PorterStemmer()  #initialize stemmer \n",
    "    lematizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(word.lower()) for word in tokenized_review if word.lower() not in stop_words])  #remove stopwords and perform stemming\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2080c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content'] = df['Content'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78276f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change datatypes if necessary\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb3ed15",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917b345",
   "metadata": {},
   "source": [
    "perform outlier analysis  \n",
    "plot which companies getting most likes  \n",
    "plot how long a tweet usuaully gets most likes  \n",
    "scatter plot to see most common amount of likes  \n",
    "plot to see if number of followers related to number of likes  \n",
    "columns=['Username', 'Content', 'No. of likes', 'No. of retweets', 'No. of replies'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier analysis\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.set_title('Tweet Likes Outliers')\n",
    "ax.boxplot(df['No. of likes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab65a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are outliers, get rid of them like this, else forget getting rid of them\n",
    "Q1 = data['World Sales (in $)'].quantile(0.25)\n",
    "Q3 = data['World Sales (in $)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "df_no_outliers = df[(df['No. of likes'] <= lower) & (df['No. of likes'] >= upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see which companies getting likes. If outliers and keeping them do violin plot otherwise do regular bargraph\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(df['Username'], df['No. of likes']) #username need to be made categorical first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of tweet vs likes\n",
    "# len_vs_likes_df = df[[len()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see where like range falling with scatterplot\n",
    "sns.lmplot(x='No. of likes', y='Username', data=df,\n",
    "           fit_reg=False, \n",
    "           hue='Username')\n",
    "plt.gcf().set_size_inches(20, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ae70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize relationship between likes and followers\n",
    "plt.subplots(figsize=(20,30))\n",
    "sns.relplot(x=\"No. of followers\", y=\"No. of likes\", kind=\"line\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930682af",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944ead4",
   "metadata": {},
   "source": [
    "Train on naive bayes and log reg (maybe svm if time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12985dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03d6490d",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afc9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5101e56",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba25c2e3",
   "metadata": {},
   "source": [
    "- https://www.sciencedirect.com/science/article/pii/S1877050920304129\n",
    "- https://www.freecodecamp.org/news/how-to-predict-likes-and-shares-based-on-your-articles-title-using-machine-learning-47f98f0612ea/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa992461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
