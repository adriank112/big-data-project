{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e04f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from string import punctuation\n",
    "from itertools import chain\n",
    "from string import digits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score,confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_regression, f_classif\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from emoji import demojize\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273a3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d10f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('testdata.manual.2009.06.14.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4e33a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7249d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['polarity', 'tweet_id', 'date', 'query', 'user', 'tweet',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ed79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['polarity', 'tweet_id', 'date', 'query', 'user', 'tweet',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a985347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  tweet_id                          date    query          user  \\\n",
       "0         4         4  Mon May 11 03:18:03 UTC 2009  kindle2        vcu451   \n",
       "1         4         5  Mon May 11 03:18:54 UTC 2009  kindle2        chadfu   \n",
       "2         4         6  Mon May 11 03:19:04 UTC 2009  kindle2         SIX15   \n",
       "3         4         7  Mon May 11 03:21:41 UTC 2009  kindle2      yamarama   \n",
       "4         4         8  Mon May 11 03:22:00 UTC 2009  kindle2  GeorgeVHulme   \n",
       "\n",
       "                                               tweet  \n",
       "0  Reading my kindle2...  Love it... Lee childs i...  \n",
       "1  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "2  @kenburbary You'll love your Kindle2. I've had...  \n",
       "3  @mikefish  Fair enough. But i have the Kindle2...  \n",
       "4  @richardebaker no. it is too big. I'm quite ha...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e610805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity    tweet_id                          date     query  \\\n",
       "0         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "            user                                              tweet  \n",
       "0  scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2        ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3         Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4       joy_wolf                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03237584",
   "metadata": {},
   "source": [
    "***\n",
    "### 1. Create sentiment column to classify the sentiment of tweets using the polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c3df9",
   "metadata": {},
   "source": [
    "According to the dataset, 0 means negative, 2 means neutral and 4 means positive. We do not need neutral tweets as they do not add value to our analysis of the tweet sentiment, so it would've been dropped, however, the dataset already had it dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea4ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 6) (799999, 6) (0, 6)\n"
     ]
    }
   ],
   "source": [
    "pos = df[df['polarity'] == 4] \n",
    "neg = df[df['polarity'] == 0]\n",
    "neutral = df[df['polarity']==2]\n",
    "print(pos.shape, neg.shape, neutral.shape)\n",
    "#Gives us insight into the polarity and how they shape the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade76eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68092</th>\n",
       "      <td>0</td>\n",
       "      <td>1692674612</td>\n",
       "      <td>Sun May 03 20:31:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lizoutline</td>\n",
       "      <td>had that nightmare again where i wake up and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336530</th>\n",
       "      <td>4</td>\n",
       "      <td>2017267875</td>\n",
       "      <td>Wed Jun 03 08:07:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>helloimwee</td>\n",
       "      <td>work bleh ha come visit today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423587</th>\n",
       "      <td>0</td>\n",
       "      <td>2062906222</td>\n",
       "      <td>Sun Jun 07 00:41:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>pempin96</td>\n",
       "      <td>School is finally over!!! :] Yet....its upsett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197113</th>\n",
       "      <td>4</td>\n",
       "      <td>1984916790</td>\n",
       "      <td>Sun May 31 16:03:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KSuds1313</td>\n",
       "      <td>@YoungQ Hope you're not missing Va Bch, DC, Jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662177</th>\n",
       "      <td>0</td>\n",
       "      <td>2243513264</td>\n",
       "      <td>Fri Jun 19 13:32:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KatyJW</td>\n",
       "      <td>I'm sad because my best friend Brittany is not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity    tweet_id                          date     query  \\\n",
       "68092           0  1692674612  Sun May 03 20:31:16 PDT 2009  NO_QUERY   \n",
       "1336530         4  2017267875  Wed Jun 03 08:07:09 PDT 2009  NO_QUERY   \n",
       "423587          0  2062906222  Sun Jun 07 00:41:55 PDT 2009  NO_QUERY   \n",
       "1197113         4  1984916790  Sun May 31 16:03:48 PDT 2009  NO_QUERY   \n",
       "662177          0  2243513264  Fri Jun 19 13:32:41 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                              tweet  \n",
       "68092    lizoutline  had that nightmare again where i wake up and m...  \n",
       "1336530  helloimwee                     work bleh ha come visit today   \n",
       "423587     pempin96  School is finally over!!! :] Yet....its upsett...  \n",
       "1197113   KSuds1313  @YoungQ Hope you're not missing Va Bch, DC, Jo...  \n",
       "662177       KatyJW  I'm sad because my best friend Brittany is not...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df) #shuffled to make the data more represntative when used for the following operations of testing, training etc.\n",
    "df.head()\n",
    "#Reference: https://towardsdatascience.com/shuffling-rows-in-pandas-dataframes-eda052275635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b096b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_map = {0:0, 4:1} #Map out values, 0 means a negative polarity, so map to 0, and 4 means positive polarity so map 4 to 1 for pos.\n",
    "y = df['polarity'].map(y_map) #Now if we do df['column'].map we transform the data 0,4 into 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6da90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d3fb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68092</th>\n",
       "      <td>0</td>\n",
       "      <td>1692674612</td>\n",
       "      <td>Sun May 03 20:31:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lizoutline</td>\n",
       "      <td>had that nightmare again where i wake up and m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336530</th>\n",
       "      <td>4</td>\n",
       "      <td>2017267875</td>\n",
       "      <td>Wed Jun 03 08:07:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>helloimwee</td>\n",
       "      <td>work bleh ha come visit today</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423587</th>\n",
       "      <td>0</td>\n",
       "      <td>2062906222</td>\n",
       "      <td>Sun Jun 07 00:41:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>pempin96</td>\n",
       "      <td>School is finally over!!! :] Yet....its upsett...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197113</th>\n",
       "      <td>4</td>\n",
       "      <td>1984916790</td>\n",
       "      <td>Sun May 31 16:03:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KSuds1313</td>\n",
       "      <td>@YoungQ Hope you're not missing Va Bch, DC, Jo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662177</th>\n",
       "      <td>0</td>\n",
       "      <td>2243513264</td>\n",
       "      <td>Fri Jun 19 13:32:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KatyJW</td>\n",
       "      <td>I'm sad because my best friend Brittany is not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity    tweet_id                          date     query  \\\n",
       "68092           0  1692674612  Sun May 03 20:31:16 PDT 2009  NO_QUERY   \n",
       "1336530         4  2017267875  Wed Jun 03 08:07:09 PDT 2009  NO_QUERY   \n",
       "423587          0  2062906222  Sun Jun 07 00:41:55 PDT 2009  NO_QUERY   \n",
       "1197113         4  1984916790  Sun May 31 16:03:48 PDT 2009  NO_QUERY   \n",
       "662177          0  2243513264  Fri Jun 19 13:32:41 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                              tweet  \\\n",
       "68092    lizoutline  had that nightmare again where i wake up and m...   \n",
       "1336530  helloimwee                     work bleh ha come visit today    \n",
       "423587     pempin96  School is finally over!!! :] Yet....its upsett...   \n",
       "1197113   KSuds1313  @YoungQ Hope you're not missing Va Bch, DC, Jo...   \n",
       "662177       KatyJW  I'm sad because my best friend Brittany is not...   \n",
       "\n",
       "         sentiment  \n",
       "68092            0  \n",
       "1336530          1  \n",
       "423587           0  \n",
       "1197113          1  \n",
       "662177           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d6d3c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity      int64\n",
       "tweet_id      int64\n",
       "date         object\n",
       "query        object\n",
       "user         object\n",
       "tweet        object\n",
       "sentiment     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd5fc9",
   "metadata": {},
   "source": [
    "***\n",
    "### 2. Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a5d29",
   "metadata": {},
   "source": [
    "1. Convert to lowercase\n",
    "2. Rmove numbers\n",
    "3. Remove punctuation marks \n",
    "4. Remove HTML tags\n",
    "5. Convert emoticons to strings\n",
    "6. Tokenize the data\n",
    "7. Remove stop words\n",
    "8. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b91540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_usernames_links(text):\n",
    "    text = re.sub('@[^\\s]+','',str(text))\n",
    "    text = re.sub('http[^\\s]+','',str(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a52cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43608914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nums(text):\n",
    "    no_nums = \"\".join([i for i in text if i not in string.digits])\n",
    "    return no_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af2efcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    no_puncts = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_puncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eda6a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    no_html_tags = soup.get_text()\n",
    "    return no_html_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d83a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    no_emoji = demojize(text)\n",
    "    return no_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36cc1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\s+', gaps = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9a050af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3018db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f042555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in en_stopwords]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "137f7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a326945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    lemmatized_text = \" \".join([lemmatizer.lemmatize(i) for i in text])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eda054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = text.apply(remove_usernames_links)\n",
    "    cleaned_text = cleaned_text.apply(convert_to_lowercase)\n",
    "    cleaned_text = cleaned_text.apply(remove_nums)\n",
    "    cleaned_text = cleaned_text.apply(remove_emojis) \n",
    "    cleaned_text = cleaned_text.apply(remove_punctuations)\n",
    "    cleaned_text = cleaned_text.apply(remove_html_tags)\n",
    "    cleaned_text = cleaned_text.apply(tokenizer.tokenize)\n",
    "    cleaned_text = cleaned_text.apply(lambda x: remove_stopwords(x))\n",
    "    cleaned_text = cleaned_text.apply(lambda x: word_lemmatizer(x))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c0815ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    cleaned_text = []\n",
    "    \n",
    "    #text = text.lower()\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_nums(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_html_tags(text)\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = word_lemmatizer(text)\n",
    "    \n",
    "    cleaned_text.append(text)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "535946ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68092      had that nightmare again where i wake up and m...\n",
       "1336530                       work bleh ha come visit today \n",
       "423587     School is finally over!!! :] Yet....its upsett...\n",
       "1197113    @YoungQ Hope you're not missing Va Bch, DC, Jo...\n",
       "662177     I'm sad because my best friend Brittany is not...\n",
       "                                 ...                        \n",
       "119448     @ChubbyGayMan I am good, just kinda tired. Try...\n",
       "304177     @millertaylor i wish i could but i don't have ...\n",
       "42082            Sending all thoughts and prayers to Layla. \n",
       "761509           is getting annoyed with always being bored \n",
       "1015627    Good morning tweeps, been real busy with work ...\n",
       "Name: tweet, Length: 1599999, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftext = df['tweet']\n",
    "dftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cc197c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = clean_text(dftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb60ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweet'] = cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06c5df5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68092</th>\n",
       "      <td>0</td>\n",
       "      <td>1692674612</td>\n",
       "      <td>Sun May 03 20:31:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lizoutline</td>\n",
       "      <td>had that nightmare again where i wake up and m...</td>\n",
       "      <td>0</td>\n",
       "      <td>nightmare wake ceiling covered spider run get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336530</th>\n",
       "      <td>4</td>\n",
       "      <td>2017267875</td>\n",
       "      <td>Wed Jun 03 08:07:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>helloimwee</td>\n",
       "      <td>work bleh ha come visit today</td>\n",
       "      <td>1</td>\n",
       "      <td>work bleh ha come visit today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423587</th>\n",
       "      <td>0</td>\n",
       "      <td>2062906222</td>\n",
       "      <td>Sun Jun 07 00:41:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>pempin96</td>\n",
       "      <td>School is finally over!!! :] Yet....its upsett...</td>\n",
       "      <td>0</td>\n",
       "      <td>school finally yetits upsetting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197113</th>\n",
       "      <td>4</td>\n",
       "      <td>1984916790</td>\n",
       "      <td>Sun May 31 16:03:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KSuds1313</td>\n",
       "      <td>@YoungQ Hope you're not missing Va Bch, DC, Jo...</td>\n",
       "      <td>1</td>\n",
       "      <td>hope youre missing va bch dc jones bch pnc sayin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662177</th>\n",
       "      <td>0</td>\n",
       "      <td>2243513264</td>\n",
       "      <td>Fri Jun 19 13:32:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KatyJW</td>\n",
       "      <td>I'm sad because my best friend Brittany is not...</td>\n",
       "      <td>0</td>\n",
       "      <td>im sad best friend brittany coming tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity    tweet_id                          date     query  \\\n",
       "68092           0  1692674612  Sun May 03 20:31:16 PDT 2009  NO_QUERY   \n",
       "1336530         4  2017267875  Wed Jun 03 08:07:09 PDT 2009  NO_QUERY   \n",
       "423587          0  2062906222  Sun Jun 07 00:41:55 PDT 2009  NO_QUERY   \n",
       "1197113         4  1984916790  Sun May 31 16:03:48 PDT 2009  NO_QUERY   \n",
       "662177          0  2243513264  Fri Jun 19 13:32:41 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                              tweet  \\\n",
       "68092    lizoutline  had that nightmare again where i wake up and m...   \n",
       "1336530  helloimwee                     work bleh ha come visit today    \n",
       "423587     pempin96  School is finally over!!! :] Yet....its upsett...   \n",
       "1197113   KSuds1313  @YoungQ Hope you're not missing Va Bch, DC, Jo...   \n",
       "662177       KatyJW  I'm sad because my best friend Brittany is not...   \n",
       "\n",
       "         sentiment                                      cleaned_tweet  \n",
       "68092            0  nightmare wake ceiling covered spider run get ...  \n",
       "1336530          1                      work bleh ha come visit today  \n",
       "423587           0                    school finally yetits upsetting  \n",
       "1197113          1   hope youre missing va bch dc jones bch pnc sayin  \n",
       "662177           0        im sad best friend brittany coming tomorrow  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ff7fb",
   "metadata": {},
   "source": [
    "***\n",
    "### Topic Modelling Using NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96b60df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_tweet']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3745edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: Lab 5\n",
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        print(\"\\n\")\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print(documents[doc_index])\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd7f91e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599999\n"
     ]
    }
   ],
   "source": [
    "documents = list(X)\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "255c0a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#TFIDF model using NMF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07258299",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "165f6f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Run NMF\n",
    "nmf_model = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "nmf_W = nmf_model.transform(tfidf)\n",
    "nmf_H = nmf_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "647a2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Topics \n",
      "\n",
      "\n",
      "Topic 0:\n",
      "day today happy great mother last school another beautiful long nice birthday tomorrow bad everyone hope first sunny mom father\n",
      "\n",
      "\n",
      "day\n",
      "\n",
      "\n",
      "day\n",
      "\n",
      "\n",
      "r u day\n",
      "\n",
      "\n",
      "wqtching e day\n",
      "\n",
      "\n",
      "day\n",
      "\n",
      "\n",
      "day\n",
      "\n",
      "\n",
      "day\n",
      "\n",
      "\n",
      "wolfvegas day\n",
      "\n",
      "\n",
      "Topic 1:\n",
      "good morning night luck everyone thats hope sound feel feeling thing time today world pretty afternoon monday weekend idea say\n",
      "\n",
      "\n",
      "good night good morning\n",
      "\n",
      "\n",
      "good morning good night\n",
      "\n",
      "\n",
      "good night good morning\n",
      "\n",
      "\n",
      "good morning good night\n",
      "\n",
      "\n",
      "good morning good night\n",
      "\n",
      "\n",
      "good night good morning\n",
      "\n",
      "\n",
      "good morning good night\n",
      "\n",
      "\n",
      "good morning good night\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "thanks follow following followfriday much great ff hey haha guy ill lol awesome aww lot ok link appreciate cool sharing\n",
      "\n",
      "\n",
      "thanks\n",
      "\n",
      "\n",
      "thanks\n",
      "\n",
      "\n",
      "thanks\n",
      "\n",
      "\n",
      "thanks steeeeeeeeeeee\n",
      "\n",
      "\n",
      "thanks\n",
      "\n",
      "\n",
      "thanks\n",
      "\n",
      "\n",
      "thanks\n",
      "\n",
      "\n",
      "thanks\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "im sorry going tired gonna sad bored sick sure still getting think happy right excited glad bed hungry hear home\n",
      "\n",
      "\n",
      "im paaaaaaaaaaaaaaain\n",
      "\n",
      "\n",
      "im\n",
      "\n",
      "\n",
      "im downnnnnlt fuckyeaaaaa\n",
      "\n",
      "\n",
      "im fandiddlytastic\n",
      "\n",
      "\n",
      "im\n",
      "\n",
      "\n",
      "im\n",
      "\n",
      "\n",
      "im boreeeeeeddddd\n",
      "\n",
      "\n",
      "im torontoagain\n",
      "\n",
      "\n",
      "Topic 4:\n",
      "get cant like time lol see got one well going really today sleep oh wait night hope need new feel\n",
      "\n",
      "\n",
      "cant get time\n",
      "\n",
      "\n",
      "cant sleep get lol\n",
      "\n",
      "\n",
      "cant wait get see\n",
      "\n",
      "\n",
      "cant get\n",
      "\n",
      "\n",
      "cant get\n",
      "\n",
      "\n",
      "cant get\n",
      "\n",
      "\n",
      "cant get\n",
      "\n",
      "\n",
      "cant get\n",
      "\n",
      "\n",
      "Topic 5:\n",
      "work back today tomorrow ready hour going getting doesnt still weekend got tired early home morning way gotta didnt week\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "work u\n",
      "\n",
      "\n",
      "yardint work\n",
      "\n",
      "\n",
      "work work work\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "Topic 6:\n",
      "love much song thank would lt guy haha new show movie happy amazing life watching girl ya id friend music\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "\n",
      "love\n",
      "\n",
      "\n",
      "Topic 7:\n",
      "know dont think feel like want let wanna even really right anymore worry people mean didnt say make haha lol\n",
      "\n",
      "\n",
      "dont know\n",
      "\n",
      "\n",
      "dont know\n",
      "\n",
      "\n",
      "dont know\n",
      "\n",
      "\n",
      "dont know\n",
      "\n",
      "\n",
      "dont know\n",
      "\n",
      "\n",
      "dont know\n",
      "\n",
      "\n",
      "dont know\n",
      "\n",
      "\n",
      "dont know\n",
      "\n",
      "\n",
      "Topic 8:\n",
      "go want home back wanna bed school sleep ready tomorrow really dont away come could wish tired see gonna rain\n",
      "\n",
      "\n",
      "want go go\n",
      "\n",
      "\n",
      "want go bamboooooozleeee\n",
      "\n",
      "\n",
      "want go\n",
      "\n",
      "\n",
      "want go\n",
      "\n",
      "\n",
      "want go\n",
      "\n",
      "\n",
      "want go\n",
      "\n",
      "\n",
      "want go\n",
      "\n",
      "\n",
      "want go\n",
      "\n",
      "\n",
      "Topic 9:\n",
      "miss much already friend gonna going baby guy home really back ill come girl lt school boyfriend boy lot old\n",
      "\n",
      "\n",
      "miss\n",
      "\n",
      "\n",
      "miss\n",
      "\n",
      "\n",
      "xaaaaaaaav miss\n",
      "\n",
      "\n",
      "miss\n",
      "\n",
      "\n",
      "miss\n",
      "\n",
      "\n",
      "miss tonysmommy dressupchallenge\n",
      "\n",
      "\n",
      "miss\n",
      "\n",
      "\n",
      "miss\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 20\n",
    "no_top_documents = 8\n",
    "print(\"NMF Topics \\n\\n\")\n",
    "display_topics(nmf_H, nmf_W, tfidf_feature_names, documents, no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d40a5",
   "metadata": {},
   "source": [
    "***\n",
    "### Classifying whether a user's tweet has a negative or positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07552749",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_n = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fadd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbaa4da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 2))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_n.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35b10060",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_n.transform(X_train)\n",
    "X_test  = tfidf_n.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76550448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess(clf_model):\n",
    "    \n",
    "    y_pred = clf_model.predict(X_test)\n",
    "    recall = recall_score(y_test,y_pred) #Calculate the recall score between actual predictions and model predictions\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print ('Model Recall: {}'.format(recall))\n",
    "    print ('Model Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53960aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = LinearSVC().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f478f6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-Top 20 positive-\n",
      "             Word  Coefficient\n",
      "        cant wait     5.331313\n",
      "      cannot wait     4.055507\n",
      "      doesnt hurt     3.466264\n",
      "wont disappointed     3.353734\n",
      "        wish luck     3.242977\n",
      "       get enough     3.077121\n",
      "    nothing wrong     2.919350\n",
      "     sick anymore     2.899433\n",
      "        can√¢ wait     2.878087\n",
      "         cant bad     2.729425\n",
      "         aint bad     2.701641\n",
      "            smile     2.701144\n",
      "      wont regret     2.688319\n",
      "        cant hurt     2.642435\n",
      "        long lost     2.616629\n",
      "      sorry delay     2.593132\n",
      "      fair enough     2.583259\n",
      "        wont hurt     2.573557\n",
      "          smiling     2.562924\n",
      "      sad anymore     2.556459\n",
      "\n",
      "-Top 20 negative-\n",
      "           Word  Coefficient\n",
      "        saddest    -3.496384\n",
      "       headache    -3.579155\n",
      "inaperfectworld    -3.613851\n",
      "         bummer    -3.634492\n",
      "  unfortunately    -3.727567\n",
      "         ruined    -3.756016\n",
      "  disappointing    -3.756258\n",
      "           cant    -3.819888\n",
      "    passed away    -3.884650\n",
      "           lost    -3.893709\n",
      "      cancelled    -3.907013\n",
      "   disappointed    -4.114127\n",
      "            rip    -4.152011\n",
      "           died    -4.159424\n",
      "        missing    -4.183698\n",
      "         bummed    -4.341920\n",
      "           sick    -4.351296\n",
      "          sadly    -4.562000\n",
      "           poor    -4.677602\n",
      "            sad    -6.004784\n"
     ]
    }
   ],
   "source": [
    "w = tfidf_n.get_feature_names()\n",
    "coef = svc_model.coef_.tolist()[0]\n",
    "coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "print('')\n",
    "print('-Top 20 positive-')\n",
    "print(coeff_df.head(20).to_string(index=False))\n",
    "print('')\n",
    "print('-Top 20 negative-')        \n",
    "print(coeff_df.tail(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1aa96de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79    199768\n",
      "           1       0.79      0.79      0.79    200232\n",
      "\n",
      "    accuracy                           0.79    400000\n",
      "   macro avg       0.79      0.79      0.79    400000\n",
      "weighted avg       0.79      0.79      0.79    400000\n",
      "\n",
      "Model Recall: 0.7929302009668784\n",
      "Model Accuracy: 0.7905675\n"
     ]
    }
   ],
   "source": [
    "assess(svc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0aca215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lgr_model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36c3efc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-Top 20 positive-\n",
      "          Word  Coefficient\n",
      "     cant wait    12.683616\n",
      "   cannot wait    11.111315\n",
      "        thanks     9.738492\n",
      "     wish luck     8.841132\n",
      "       smiling     7.953867\n",
      "congratulation     7.926818\n",
      "          glad     7.546843\n",
      "     wasnt bad     7.534480\n",
      "     dont miss     7.394682\n",
      "       excited     7.279660\n",
      " nothing wrong     7.226360\n",
      "    get enough     7.179144\n",
      "   dont forget     6.974525\n",
      "      isnt bad     6.974214\n",
      "       amazing     6.962698\n",
      "         thank     6.947529\n",
      "       welcome     6.528431\n",
      "           yay     6.458659\n",
      "  followfriday     6.349990\n",
      "      made day     6.346258\n",
      "\n",
      "-Top 20 negative-\n",
      "         Word  Coefficient\n",
      "disappointing    -9.631143\n",
      "         suck    -9.730674\n",
      "       bummer    -9.731106\n",
      "unfortunately   -10.032774\n",
      "         hurt   -10.121871\n",
      "       ruined   -10.462240\n",
      "      missing   -10.516198\n",
      "         died   -10.559800\n",
      "    cancelled   -10.600008\n",
      "   depressing   -10.668919\n",
      " disappointed   -10.959266\n",
      "       gutted   -10.962342\n",
      "         lost   -11.008033\n",
      "         cant   -11.342988\n",
      "         sick   -11.905955\n",
      "          rip   -11.966400\n",
      "       bummed   -12.123883\n",
      "         miss   -12.866398\n",
      "        sadly   -13.589583\n",
      "          sad   -19.459903\n"
     ]
    }
   ],
   "source": [
    "w = tfidf_n.get_feature_names()\n",
    "coef = lgr_model.coef_.tolist()[0]\n",
    "coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "print('')\n",
    "print('-Top 20 positive-')\n",
    "print(coeff_df.head(20).to_string(index=False))\n",
    "print('')\n",
    "print('-Top 20 negative-')        \n",
    "print(coeff_df.tail(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7387255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80    199768\n",
      "           1       0.79      0.80      0.80    200232\n",
      "\n",
      "    accuracy                           0.80    400000\n",
      "   macro avg       0.80      0.80      0.80    400000\n",
      "weighted avg       0.80      0.80      0.80    400000\n",
      "\n",
      "Model Recall: 0.8048313955811259\n",
      "Model Accuracy: 0.7977575\n"
     ]
    }
   ],
   "source": [
    "assess(lgr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7fced2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(tfidf_n, model, text):\n",
    "    tweet = tfidf_n.transform(clean(text))\n",
    "    sentiment = model.predict(tweet)\n",
    "    posp = \"Positive Sentiment\"\n",
    "    negp = \"Negative Sentiment\"\n",
    "    \n",
    "    if sentiment == 0:\n",
    "        return negp\n",
    "    if sentiment == 1:\n",
    "        return posp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20596629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative Sentiment'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enter your tweet to predict the sentiment:\n",
    "tweet = [\"I hate puppies\"]\n",
    "predict_sentiment(tfidf_n, svc_model, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da237644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive Sentiment'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enter your tweet to predict the sentiment:\n",
    "tweet = [\"I love puppies\"]\n",
    "predict_sentiment(tfidf_n, svc_model, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3aeed5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative Sentiment'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enter your tweet to predict the sentiment:\n",
    "tweet = [\"I hate puppies\"]\n",
    "predict_sentiment(tfidf_n, lgr_model, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "683ebfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive Sentiment'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enter your tweet to predict the sentiment:\n",
    "tweet = [\"I love puppies\"]\n",
    "predict_sentiment(tfidf_n, lgr_model, tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e454be",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "* Lab 5\n",
    "* https://dylancastillo.co/nlp-snippets-clean-and-tokenize-text-with-python/#transform-emojis-to-characters\n",
    "* https://machinelearningmastery.com/how-to-connect-model-input-data-with-predictions-for-machine-learning/\n",
    "* https://www.academia.edu/74585014/Machine_Learning_Approach_to_Sentiment_Analysis_from_Movie_Reviews_Using_Word2Vec\n",
    "* https://entertainment.bacsigan.com/popedaze/sentiment-analysis-in-python\n",
    "* https://www.w3schools.com/python/python_lists_add.asp\n",
    "* https://stackoverflow.com/questions/32106063/sklearn-linearsvc-x-has-1-features-per-sample-expecting-5\n",
    "* https://datascience.stackexchange.com/questions/51224/why-does-transform-from-tfidf-vectorizer-sklearn-not-work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854391b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
