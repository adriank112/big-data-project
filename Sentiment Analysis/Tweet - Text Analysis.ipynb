{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2e04f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from string import punctuation\n",
    "from itertools import chain\n",
    "from string import digits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_regression, f_classif\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273a3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4e33a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b7249d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['polarity', 'tweet_id', 'date', 'query', 'user', 'tweet',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e610805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity    tweet_id                          date     query  \\\n",
       "0         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "            user                                              tweet  \n",
       "0  scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2        ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3         Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4       joy_wolf                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03237584",
   "metadata": {},
   "source": [
    "***\n",
    "### 1. Create sentiment column to classify the sentiment of tweets using the polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c3df9",
   "metadata": {},
   "source": [
    "According to the dataset, 0 means negative, 2 means neutral and 4 means positive. We do not need neutral tweets as they do not add value to our analysis of the tweet sentiment, so it would've been dropped, however, the dataset already had it dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea4ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 6) (799999, 6) (0, 6)\n"
     ]
    }
   ],
   "source": [
    "pos = df[df['polarity'] == 4] \n",
    "neg = df[df['polarity'] == 0]\n",
    "neutral = df[df['polarity']==2]\n",
    "print(pos.shape, neg.shape, neutral.shape)\n",
    "#Gives us insight into the ratings and how they shape the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade76eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>956413</th>\n",
       "      <td>4</td>\n",
       "      <td>1825221880</td>\n",
       "      <td>Sun May 17 04:51:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>xlove_katiex</td>\n",
       "      <td>that voice in side your head saying... your ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426253</th>\n",
       "      <td>0</td>\n",
       "      <td>2063496279</td>\n",
       "      <td>Sun Jun 07 02:53:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Headphaze</td>\n",
       "      <td>My tweets from the Meadows Festival have arriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592208</th>\n",
       "      <td>0</td>\n",
       "      <td>2217890027</td>\n",
       "      <td>Wed Jun 17 21:32:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>FreightTrainn</td>\n",
       "      <td>Ew. There is a massive slug thing on my side w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785687</th>\n",
       "      <td>0</td>\n",
       "      <td>2324489615</td>\n",
       "      <td>Thu Jun 25 03:17:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>hambers</td>\n",
       "      <td>@g33kgurrl Man, I hate that. Arghhh.  I was tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302537</th>\n",
       "      <td>0</td>\n",
       "      <td>1999059667</td>\n",
       "      <td>Mon Jun 01 19:34:24 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ally_KM</td>\n",
       "      <td>@4hoursstanding Feeling horrible today but I l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity    tweet_id                          date     query  \\\n",
       "956413         4  1825221880  Sun May 17 04:51:55 PDT 2009  NO_QUERY   \n",
       "426253         0  2063496279  Sun Jun 07 02:53:52 PDT 2009  NO_QUERY   \n",
       "592208         0  2217890027  Wed Jun 17 21:32:40 PDT 2009  NO_QUERY   \n",
       "785687         0  2324489615  Thu Jun 25 03:17:08 PDT 2009  NO_QUERY   \n",
       "302537         0  1999059667  Mon Jun 01 19:34:24 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                              tweet  \n",
       "956413   xlove_katiex  that voice in side your head saying... your ju...  \n",
       "426253      Headphaze  My tweets from the Meadows Festival have arriv...  \n",
       "592208  FreightTrainn  Ew. There is a massive slug thing on my side w...  \n",
       "785687        hambers  @g33kgurrl Man, I hate that. Arghhh.  I was tr...  \n",
       "302537        Ally_KM  @4hoursstanding Feeling horrible today but I l...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df) #shuffled to make the data more represntative when used for the following operations of testing, training etc.\n",
    "df.head()\n",
    "#Reference: https://towardsdatascience.com/shuffling-rows-in-pandas-dataframes-eda052275635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b096b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_map = {0:0, 4:1} #Map out values, 1 and 2 should map to 0 meaning a negative review, and 4 and 5 map to 1 for pos.\n",
    "y = df['polarity'].map(y_map) #Now if we do df['column'].map we transform the data 1,2,4,5 into 0 and 1 making it binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6da90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97d3fb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>956413</th>\n",
       "      <td>4</td>\n",
       "      <td>1825221880</td>\n",
       "      <td>Sun May 17 04:51:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>xlove_katiex</td>\n",
       "      <td>that voice in side your head saying... your ju...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426253</th>\n",
       "      <td>0</td>\n",
       "      <td>2063496279</td>\n",
       "      <td>Sun Jun 07 02:53:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Headphaze</td>\n",
       "      <td>My tweets from the Meadows Festival have arriv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592208</th>\n",
       "      <td>0</td>\n",
       "      <td>2217890027</td>\n",
       "      <td>Wed Jun 17 21:32:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>FreightTrainn</td>\n",
       "      <td>Ew. There is a massive slug thing on my side w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785687</th>\n",
       "      <td>0</td>\n",
       "      <td>2324489615</td>\n",
       "      <td>Thu Jun 25 03:17:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>hambers</td>\n",
       "      <td>@g33kgurrl Man, I hate that. Arghhh.  I was tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302537</th>\n",
       "      <td>0</td>\n",
       "      <td>1999059667</td>\n",
       "      <td>Mon Jun 01 19:34:24 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ally_KM</td>\n",
       "      <td>@4hoursstanding Feeling horrible today but I l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity    tweet_id                          date     query  \\\n",
       "956413         4  1825221880  Sun May 17 04:51:55 PDT 2009  NO_QUERY   \n",
       "426253         0  2063496279  Sun Jun 07 02:53:52 PDT 2009  NO_QUERY   \n",
       "592208         0  2217890027  Wed Jun 17 21:32:40 PDT 2009  NO_QUERY   \n",
       "785687         0  2324489615  Thu Jun 25 03:17:08 PDT 2009  NO_QUERY   \n",
       "302537         0  1999059667  Mon Jun 01 19:34:24 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                              tweet  \\\n",
       "956413   xlove_katiex  that voice in side your head saying... your ju...   \n",
       "426253      Headphaze  My tweets from the Meadows Festival have arriv...   \n",
       "592208  FreightTrainn  Ew. There is a massive slug thing on my side w...   \n",
       "785687        hambers  @g33kgurrl Man, I hate that. Arghhh.  I was tr...   \n",
       "302537        Ally_KM  @4hoursstanding Feeling horrible today but I l...   \n",
       "\n",
       "        sentiment  \n",
       "956413          1  \n",
       "426253          0  \n",
       "592208          0  \n",
       "785687          0  \n",
       "302537          0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d6d3c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity      int64\n",
       "tweet_id      int64\n",
       "date         object\n",
       "query        object\n",
       "user         object\n",
       "tweet        object\n",
       "sentiment     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd5fc9",
   "metadata": {},
   "source": [
    "***\n",
    "### 2. Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a5d29",
   "metadata": {},
   "source": [
    "1. Convert to lowercase\n",
    "2. Rmove numbers\n",
    "3. Remove punctuation marks \n",
    "4. Remove HTML tags\n",
    "5. Convert emoticons to strings\n",
    "6. Tokenize the data\n",
    "7. Remove stop words\n",
    "8. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a52cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43608914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nums(text):\n",
    "    no_nums = \"\".join([i for i in text if i not in string.digits])\n",
    "    return no_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af2efcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    no_puncts = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_puncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eda6a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    no_html_tags = soup.get_text()\n",
    "    return no_html_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7178ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###REPLACE EMOTICONS, HOWEVER, THE DATASET ALREADY REPLACED THEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36cc1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3018db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f042555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in en_stopwords]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "137f7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a326945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(text):\n",
    "    stemmed_text = \" \".join([ps.stem(i) for i in text])\n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1eda054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = text.apply(convert_to_lowercase)\n",
    "    cleaned_text = cleaned_text.apply(remove_nums)\n",
    "    cleaned_text = cleaned_text.apply(remove_punctuations)\n",
    "    cleaned_text = cleaned_text.apply(remove_html_tags)\n",
    "    cleaned_text = cleaned_text.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "    cleaned_text = cleaned_text.apply(lambda x: remove_stopwords(x))\n",
    "    cleaned_text = cleaned_text.apply(lambda x: word_stemmer(x))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "535946ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956413    that voice in side your head saying... your ju...\n",
       "426253    My tweets from the Meadows Festival have arriv...\n",
       "592208    Ew. There is a massive slug thing on my side w...\n",
       "785687    @g33kgurrl Man, I hate that. Arghhh.  I was tr...\n",
       "302537    @4hoursstanding Feeling horrible today but I l...\n",
       "                                ...                        \n",
       "336765    @ahmedzainal oh noooooo that will bring lots o...\n",
       "276482        Grrrrrr. iPod still in UPS' hub in Cologne!! \n",
       "466467    bloody hell, made a cuppa and put it down and ...\n",
       "929837          @wantsum67 i'm ready for the back rub..... \n",
       "29586     shit the metric show is on tues and i didnt en...\n",
       "Name: tweet, Length: 1599999, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftext = df['tweet']\n",
    "dftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0cc197c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = clean_text(dftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb60ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweet'] = cleaned_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06c5df5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>956413</th>\n",
       "      <td>4</td>\n",
       "      <td>1825221880</td>\n",
       "      <td>Sun May 17 04:51:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>xlove_katiex</td>\n",
       "      <td>that voice in side your head saying... your ju...</td>\n",
       "      <td>1</td>\n",
       "      <td>voic side head say justjust dummyyyy hm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426253</th>\n",
       "      <td>0</td>\n",
       "      <td>2063496279</td>\n",
       "      <td>Sun Jun 07 02:53:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Headphaze</td>\n",
       "      <td>My tweets from the Meadows Festival have arriv...</td>\n",
       "      <td>0</td>\n",
       "      <td>tweet meadow festiv arriv late must got stuck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592208</th>\n",
       "      <td>0</td>\n",
       "      <td>2217890027</td>\n",
       "      <td>Wed Jun 17 21:32:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>FreightTrainn</td>\n",
       "      <td>Ew. There is a massive slug thing on my side w...</td>\n",
       "      <td>0</td>\n",
       "      <td>ew massiv slug thing side walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785687</th>\n",
       "      <td>0</td>\n",
       "      <td>2324489615</td>\n",
       "      <td>Thu Jun 25 03:17:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>hambers</td>\n",
       "      <td>@g33kgurrl Man, I hate that. Arghhh.  I was tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>gkgurrl man hate arghhh tri demo yesterday dam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302537</th>\n",
       "      <td>0</td>\n",
       "      <td>1999059667</td>\n",
       "      <td>Mon Jun 01 19:34:24 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Ally_KM</td>\n",
       "      <td>@4hoursstanding Feeling horrible today but I l...</td>\n",
       "      <td>0</td>\n",
       "      <td>hoursstand feel horribl today look like pirat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity    tweet_id                          date     query  \\\n",
       "956413         4  1825221880  Sun May 17 04:51:55 PDT 2009  NO_QUERY   \n",
       "426253         0  2063496279  Sun Jun 07 02:53:52 PDT 2009  NO_QUERY   \n",
       "592208         0  2217890027  Wed Jun 17 21:32:40 PDT 2009  NO_QUERY   \n",
       "785687         0  2324489615  Thu Jun 25 03:17:08 PDT 2009  NO_QUERY   \n",
       "302537         0  1999059667  Mon Jun 01 19:34:24 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                              tweet  \\\n",
       "956413   xlove_katiex  that voice in side your head saying... your ju...   \n",
       "426253      Headphaze  My tweets from the Meadows Festival have arriv...   \n",
       "592208  FreightTrainn  Ew. There is a massive slug thing on my side w...   \n",
       "785687        hambers  @g33kgurrl Man, I hate that. Arghhh.  I was tr...   \n",
       "302537        Ally_KM  @4hoursstanding Feeling horrible today but I l...   \n",
       "\n",
       "        sentiment                                      cleaned_tweet  \n",
       "956413          1            voic side head say justjust dummyyyy hm  \n",
       "426253          0  tweet meadow festiv arriv late must got stuck ...  \n",
       "592208          0                     ew massiv slug thing side walk  \n",
       "785687          0  gkgurrl man hate arghhh tri demo yesterday dam...  \n",
       "302537          0  hoursstand feel horribl today look like pirat ...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857a18d",
   "metadata": {},
   "source": [
    "***\n",
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c69a240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: Lab 5\n",
    "def text_fit(X, y, model, clf_model, coef_show=1): \n",
    "    X_c = model.fit_transform(X) \n",
    "    print('# features: {}'.format(X_c.shape[1]))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_c, y, random_state=0) #Splits the data into one for training and one for testing\n",
    "    print('# train records: {}'.format(X_train.shape[0]))\n",
    "    print('# test records: {}'.format(X_test.shape[0]))\n",
    "    clf = clf_model.fit(X_train, y_train) #Fir the logistic reg model with the training data\n",
    "    y_pred = clf.predict(X_test)  #Prediction using the Test data\n",
    "    recall = recall_score(y_test,y_pred) #Calculate the recall score between actual predictions and model predictions\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    f1score = f1_score(y_test, y_pred) \n",
    "    print ('Model Recall: {}'.format(recall))\n",
    "    if coef_show == 1:  #Extract the coefficients from the model and put it in a dataframe\n",
    "        #print(confusion_matrix(y_test, y_pred))\n",
    "        w = model.get_feature_names()\n",
    "        coef = clf.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print('-Top 20 positive-')\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print('-Top 20 negative-')        \n",
    "        print(coeff_df.tail(20).to_string(index=False))\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b589f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_tweet']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ff0e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a50a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_n = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2297cb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 5200732\n",
      "# train records: 1199999\n",
      "# test records: 400000\n",
      "Model Recall: 0.8192872243129377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-Top 20 positive-\n",
      "           Word  Coefficient\n",
      "      cant wait     6.323890\n",
      "      wish luck     4.311233\n",
      "    cannot wait     4.296175\n",
      "    doesnt hurt     4.209040\n",
      "          thank     3.773866\n",
      "     dont worri     3.721359\n",
      "wont disappoint     3.497343\n",
      "        sad sad     3.492039\n",
      "     noth wrong     3.463514\n",
      "       isnt bad     3.433893\n",
      "    dont forget     3.374591\n",
      "          smile     3.308028\n",
      "      wasnt bad     3.243278\n",
      "     sad anymor     3.075254\n",
      "     never fail     3.012563\n",
      "      dont miss     2.968744\n",
      "       aint bad     2.928135\n",
      "    wont regret     2.908489\n",
      "       cant bad     2.850790\n",
      "    fair enough     2.842829\n",
      "\n",
      "-Top 20 negative-\n",
      "      Word  Coefficient\n",
      "       cri    -3.901289\n",
      "     broke    -3.946179\n",
      "      suck    -3.977304\n",
      "     upset    -3.977613\n",
      "      hurt    -4.034242\n",
      "    bummer    -4.068395\n",
      "      hate    -4.086650\n",
      "    cancel    -4.138764\n",
      "      lost    -4.311724\n",
      "       rip    -4.312589\n",
      "   depress    -4.360937\n",
      "      sick    -4.492867\n",
      "disappoint    -4.510793\n",
      "      wish    -4.518805\n",
      "  unfortun    -4.882962\n",
      "      cant    -5.137057\n",
      "     sadli    -5.288394\n",
      "      poor    -5.347768\n",
      "      miss    -5.681235\n",
      "       sad    -7.885089\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf_n = text_fit(X, y, tfidf_n, LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04e9d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 5200732\n",
      "# train records: 1199999\n",
      "# test records: 400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Recall: 0.8266488747619833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-Top 20 positive-\n",
      "       Word  Coefficient\n",
      "  cant wait    16.132923\n",
      "      thank    13.052376\n",
      "  wish luck     9.584853\n",
      "     welcom     8.988087\n",
      "      smile     8.921259\n",
      "cannot wait     8.436763\n",
      "     awesom     7.600849\n",
      "       love     7.500623\n",
      " dont worri     7.484573\n",
      "       hehe     7.418901\n",
      "  wasnt bad     7.354722\n",
      "        yay     7.089457\n",
      "    congrat     6.910141\n",
      "dont forget     6.866258\n",
      "   isnt bad     6.838272\n",
      " noth wrong     6.826312\n",
      "  congratul     6.743924\n",
      "  dont miss     6.678214\n",
      "      proud     6.472509\n",
      "      excit     6.444141\n",
      "\n",
      "-Top 20 negative-\n",
      "      Word  Coefficient\n",
      "     sorri    -9.134026\n",
      "       rip    -9.156481\n",
      "      lost    -9.390140\n",
      "disappoint    -9.458118\n",
      "   depress    -9.483757\n",
      "       cri    -9.677994\n",
      "      hurt    -9.760371\n",
      "       ugh    -9.914124\n",
      "     broke   -10.131570\n",
      "      suck   -10.170157\n",
      "   headach   -10.180339\n",
      "  unfortun   -10.453134\n",
      "      sick   -10.661646\n",
      "     sadli   -10.867687\n",
      "      hate   -11.599040\n",
      "      wish   -12.517673\n",
      "      cant   -12.905378\n",
      "      poor   -14.213006\n",
      "      miss   -17.070738\n",
      "       sad   -19.967077\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf_n = text_fit(X, y, tfidf_n, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646b9c0",
   "metadata": {},
   "source": [
    "***\n",
    "### Topic Modelling Using NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8d4db991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: Lab 5\n",
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        print(\"\\n\")\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print(documents[doc_index])\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d70f619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599999\n"
     ]
    }
   ],
   "source": [
    "documents = list(X)\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f5777365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#TFIDF model using NMF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "36727dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d9c91748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adria\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Run NMF\n",
    "nmf_model = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "nmf_W = nmf_model.transform(tfidf)\n",
    "nmf_H = nmf_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "36ca32de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Topics \n",
      "\n",
      "\n",
      "Topic 0:\n",
      "im sorri tire gonna bore sad think sick still sure happi lol right excit realli glad hungri watch haha oh\n",
      "\n",
      "\n",
      "isabelbm im\n",
      "\n",
      "\n",
      "im im\n",
      "\n",
      "\n",
      "yepcaitlinburn im\n",
      "\n",
      "\n",
      "im jblphotograpghi\n",
      "\n",
      "\n",
      "Topic 1:\n",
      "work back today tomorrow hour still weekend readi doesnt home tire bore got earli week way sunday hard isnt tri\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "work\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "good morn night luck everyon hope feel time that today sound look world thing twitter last bed pretti afternoon great\n",
      "\n",
      "\n",
      "pixiepop good morn good night\n",
      "\n",
      "\n",
      "good morn good night\n",
      "\n",
      "\n",
      "good night good morn\n",
      "\n",
      "\n",
      "good morn good night\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "go want bed home wanna tomorrow school back sleep see today tonight wish rain away shop beach night readi soon\n",
      "\n",
      "\n",
      "go studiofin\n",
      "\n",
      "\n",
      "go\n",
      "\n",
      "\n",
      "go\n",
      "\n",
      "\n",
      "ammagawd go\n",
      "\n",
      "\n",
      "Topic 4:\n",
      "day today happi mother last great school anoth long beauti nice tomorrow bad hope one everyon birthday first rain start\n",
      "\n",
      "\n",
      "day\n",
      "\n",
      "\n",
      "beautifaul day\n",
      "\n",
      "\n",
      "epicphenom day\n",
      "\n",
      "\n",
      "day vacationwoooooohoooooo\n",
      "\n",
      "\n",
      "Topic 5:\n",
      "dont feel like know want realli think well look today make bad better lol sick one right hate wanna doesnt\n",
      "\n",
      "\n",
      "feel like dont know u\n",
      "\n",
      "\n",
      "mmmmhno dont feel like\n",
      "\n",
      "\n",
      "dont like feel\n",
      "\n",
      "\n",
      "realli dont like morningsi dont feel well\n",
      "\n",
      "\n",
      "Topic 6:\n",
      "thank follow much followfriday great god hey lol appreci tweet everyon ff haha guy awesom ill your help hope twitter\n",
      "\n",
      "\n",
      "missreena thank\n",
      "\n",
      "\n",
      "nightingalehh thank\n",
      "\n",
      "\n",
      "rwyn thank\n",
      "\n",
      "\n",
      "mpappa thank\n",
      "\n",
      "\n",
      "Topic 7:\n",
      "miss much alreadi friend babi realli home gonna sad guy back ill last girl show come boy boyfriend lt fun\n",
      "\n",
      "\n",
      "miss\n",
      "\n",
      "\n",
      "msmonogram miss\n",
      "\n",
      "\n",
      "alexsensei miss\n",
      "\n",
      "\n",
      "miss httpbitlypbztg\n",
      "\n",
      "\n",
      "Topic 8:\n",
      "love much song new watch would lt movi haha guy show life friend weather amaz happi amp great make girl\n",
      "\n",
      "\n",
      "usmccowgirl love\n",
      "\n",
      "\n",
      "httpbitlyhoi love\n",
      "\n",
      "\n",
      "twitterchatsess love\n",
      "\n",
      "\n",
      "tiffanyboz love\n",
      "\n",
      "\n",
      "Topic 9:\n",
      "get cant time back sleep wait got see home need night new twitter one readi come hope last tomorrow still\n",
      "\n",
      "\n",
      "get cant\n",
      "\n",
      "\n",
      "cant get\n",
      "\n",
      "\n",
      "cant get\n",
      "\n",
      "\n",
      "cant get ltdf\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 20\n",
    "no_top_documents = 4\n",
    "print(\"NMF Topics \\n\\n\")\n",
    "display_topics(nmf_H, nmf_W, tfidf_feature_names, documents, no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a464c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
